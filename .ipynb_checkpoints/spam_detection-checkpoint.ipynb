{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "import findspark, random\n",
    "findspark.init(\"\")\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext(appName=\"Assignment5\", master=\"local[2]\", conf=SparkConf().set('spark.ui.port', random.randrange(4000,5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "\n",
    "def sequential_SGD(model, training_dataset='', delta = 0.002):\n",
    "    #### Your solution to Question 1 here\n",
    "    # open one of the training files - defaults to group_x\n",
    "    with open(training_dataset) as f:\n",
    "        #iterate through each line in the file\n",
    "        for line in f:\n",
    "            #separate the label and features and calculate the probability of spam or ham\n",
    "            doc = line.split()\n",
    "            t = doc[1]\n",
    "            F = doc[2:]\n",
    "            F = [int(feat) for feat in F]#convert features to integers\n",
    "            score = spamminess(F,model)\n",
    "            prob = 1.0/(1+exp(-score))\n",
    "            #update the model weights based on the current documents label\n",
    "            for feature in F:\n",
    "                if t == 'spam':\n",
    "                    if feature not in model:\n",
    "                        model[feature] = (1.0-prob)*delta\n",
    "                    else:\n",
    "                        model[feature]+= (1.0-prob)*delta\n",
    "                elif t=='ham':\n",
    "                    if feature not in model:\n",
    "                        model[feature] = (-prob)*delta\n",
    "                    else:\n",
    "                        model[feature]-= prob*delta\n",
    "                    \n",
    "    #   for line in f:\n",
    "    #      each line represents a document\n",
    "    #      read and parse the line\n",
    "    #      Let:\n",
    "    #        t represent the spam/ham tag for this document\n",
    "    #        F represent the list of features for this document\n",
    "\n",
    "    #      find the spamminess of the current document using the current model:\n",
    "    #      score = spamminess(F,w)\n",
    "\n",
    "    #      then, update the model:\n",
    "    #      prob = 1.0/(1+exp(-score))\n",
    "    #      for each feature f in F:\n",
    "    #          if t == 'spam':\n",
    "    #              increase model(f) by (1.0-prob)*delta (or set model(f) to (1.0-prob)*delta if f is not in the dict yet)\n",
    "    #          elif t == 'ham':\n",
    "    #              decrease model(f) by prob*delta (or set model(f) to -prob*delta if f is not in the dict yet)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "scrolled": true,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387908 0.00695474119501872\n",
      "697162 0.00695474119501872\n",
      "426572 0.00695474119501872\n",
      "161118 0.00695474119501872\n",
      "688171 0.00695474119501872\n",
      "43992 0.00695474119501872\n",
      "908749 0.00695474119501872\n",
      "126841 0.00695474119501872\n",
      "116309 0.00695474119501872\n",
      "950728 0.00695474119501872\n",
      "394920 0.00695474119501872\n",
      "358453 0.00695474119501872\n",
      "23565 0.00695474119501872\n",
      "210162 0.01394765848836145\n",
      "861926 0.013942427517810815\n",
      "177667 0.00695474119501872\n",
      "284634 0.00695474119501872\n",
      "358345 0.00695474119501872\n",
      "971891 0.00695474119501872\n",
      "646357 0.00695474119501872\n",
      "599737 0.00695474119501872\n",
      "957529 0.00695474119501872\n",
      "970014 0.00695474119501872\n",
      "449273 0.00695474119501872\n",
      "129997 0.00695474119501872\n",
      "244086 0.00695474119501872\n",
      "529524 0.00695474119501872\n",
      "170675 0.00695474119501872\n",
      "126503 0.00695474119501872\n",
      "455001 0.00695474119501872\n",
      "648917 0.00695474119501872\n",
      "255018 0.00695474119501872\n",
      "716613 0.007877239977721872\n",
      "106120 0.007877239977721872\n",
      "310307 0.007877239977721872\n",
      "318741 0.007877239977721872\n",
      "169946 0.0015770186928456198\n",
      "648441 0.0027379039388857767\n",
      "469266 0.006245550469242465\n",
      "223606 0.005791698078662205\n",
      "44048 0.005791698078662205\n",
      "862449 0.0055929367217610534\n",
      "206323 0.007362468430580575\n",
      "199001 0.007362468430580575\n",
      "847020 0.005608737005566581\n",
      "256774 -0.0008838279224116023\n",
      "113458 0.0012054274476693285\n",
      "115701 0.0021686532230599438\n",
      "795147 0.002187311319370932\n",
      "277948 0.002187311319370932\n"
     ]
    }
   ],
   "source": [
    "# Your tests here\n",
    "#Question 1\n",
    "i=0\n",
    "w = sequential_SGD({}) # Providing an empty model\n",
    "for k,v in w.items():\n",
    "    print(k,v)\n",
    "    i+=1\n",
    "    if i==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "#### Question 2 (5/20 marks)\n",
    "\n",
    "Next, you should try implementing a Spark version of the SGD model trainer.   Before you start, create a new folder\n",
    "called `models` inside your cs431 folder.   Your Spark implementation should read a training file, train the model, and then output the model to the models folder.  The model output file that you generate should list the weight associated with each feature, with one feature per line, like this:\n",
    "```\n",
    "(802123, 0.0009858585991850937)\n",
    "(438450, 4.267897922108138e-05)\n",
    "(271525, 0.0013133437007968654)\n",
    "(92853, 0.0004300009932503611)\n",
    "```\n",
    "\n",
    "Use Spark's `saveAsTextFile` action to output your model.   For example, if you are training a model for the group_x training set, use `saveAsTextFile(\"models/group_x_model\")`.   This will actually cause Spark to create a folder called `group_x_model`.   In the folder, there will be files with names like `part-00000` that contain the actual output data.  When you use `saveAsTextFile`, Spark will generate one `part-xxxxx` file for each partition of the RDD that you are writing out.   In this case, you should have only a single partition (for the reason described below), so there should be only one `part-xxxxx` file.\n",
    "\n",
    "Training the SGD model is an inherently sequential task, since the training instances update the model one at a time, and each instance's spamminess is computed using the model produced by that instance's predecessors.   This means that the only part of the training that you can parallelize using Spark is the parsing of the input file.   Once the input is parsed, your Spark implementation will have to force all of the instances into a single partition, and then apply the training function to the entire partition.   To see whether you are getting sensible results, you can compare the model you learn with Spark to the one that you learned with your sequential Python program from Question 1.\n",
    "\n",
    "Remember that training should occur entirely in Spark.  The training instances should never come into your driver program.\n",
    "\n",
    "Implement the function `spark_SGD()` below that takes as input the path to the training dataset, an output path `output_model` and a value for the update parameter `delta`, and writes the trained model to `output_model` using Spark's `saveAsTextFile`. You can use it to generate models from all three of the training files, leaving the results in your models folder. For this assignment, you will be using Spark's original RDD interface, rather than the DataFrame interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "import shutil, os\n",
    "\n",
    "def spark_SGD(training_dataset='', output_model='models/group_x_model', delta = 0.002):\n",
    "    #helper function to calculate probability and update the model weights\n",
    "    def update(x):\n",
    "        model_Q2={}#dictionary to store the (features,weights) pairs\n",
    "        for line in x:\n",
    "            t = line[0]\n",
    "            F = line[1]\n",
    "            F = [int(feat) for feat in F]#convert feats to ints\n",
    "            score = spamminess(F,model_Q2)\n",
    "            prob = 1.0/(1+exp(-score))\n",
    "            #update the model weights based on the current documents label\n",
    "            for feature in F:\n",
    "                if t == 'spam':\n",
    "                    if feature not in model_Q2:\n",
    "                        model_Q2[feature] = (1.0-prob)*delta\n",
    "                    else:\n",
    "                        model_Q2[feature]+= (1.0-prob)*delta\n",
    "                elif t=='ham':\n",
    "                    if feature not in model_Q2:\n",
    "                        model_Q2[feature] = (-prob)*delta\n",
    "                    else:\n",
    "                        model_Q2[feature]-= prob*delta\n",
    "        yield model_Q2#return a generator containing all (features,weights) pairs\n",
    "\n",
    "    \n",
    "    if os.path.isdir(output_model):\n",
    "        shutil.rmtree(output_model) # Remove the previous model to create a new one\n",
    "    training_data = sc.textFile(training_dataset)#read dataset\n",
    "    labelFeature_rdd = training_data.map(lambda line:line.split()).map(lambda line:(line[1],line[2:])).coalesce(1)#obtain labels&features and combine all instances into 1 partition\n",
    "    update_model = labelFeature_rdd.mapPartitions(update).flatMap(lambda line:[(int(k),v) for k,v in line.items()])#call function on whole partition\n",
    "    update_model.saveAsTextFile(output_model)#save the model as text file\n",
    "    #### Your Solution to Question 2 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "scrolled": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# Your tests here\n",
    "spark_SGD()\n",
    "spark_SGD(training_dataset='', output_model='models/group_y_model')\n",
    "spark_SGD(training_dataset='', output_model='models/britney_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "#### Question 3 (5/20 marks)\n",
    "\n",
    "When you train a model using SGD, the model you get depends on the order in which you handle the training instances.  To see this in action, try using the Spark SGD trainer you implemented for Question 2 to train a model from the group_x training set, but with the instances processed in a different order.  \n",
    "\n",
    "To do this, re-implement your trainer from Question 2 so that it will randomly reorder the training instances before using them to update the model. One way to shuffle the training instances is to assign a random sort key to each training instance as you read it from the input file, and then sort the instances using the random sort key.\n",
    "\n",
    "Be sure that Spark is doing the work of shuffling the training instances.   Do not load the training instances into your driver program and sort them there.\n",
    "\n",
    "Implement the function `spark_shuffled_SGD` below that takes as input the path to the training dataset, an output path `output_model` and a value for the update parameter `delta`, shuffles the training instances using the method described above and writes the trained model to `output_model` using Spark's `saveAsTextFile`.\n",
    "\n",
    "Once you have implemented the shuffled trainer, train a model using shuffled group_x training instances, and compare the resulting model with group_x model you learned without shuffling.  It is up to you how to do this comparision.  At a minimum, compare features with the highest weights in each model to see if they are similar. You can also use the classifier in next question to classify documents using the two models, and compare results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "import shutil, os, random\n",
    "\n",
    "def spark_shuffled_SGD(training_dataset='', output_model='models/group_x_model', delta = 0.002):\n",
    "    #helper function to calculate probability and update the model weights\n",
    "    def update(x):\n",
    "        model_Q2={}#dictionary to store the (features,weights) pairs\n",
    "        for line in x:\n",
    "            t = line[0]\n",
    "            F = line[1]\n",
    "            F = [int(feat) for feat in F]#convert feats to ints\n",
    "            score = spamminess(F,model_Q2)\n",
    "            prob = 1.0/(1+exp(-score))\n",
    "            #update the model weights based on the current documents label\n",
    "            for feature in F:\n",
    "                if t == 'spam':\n",
    "                    if feature not in model_Q2:\n",
    "                        model_Q2[feature] = (1.0-prob)*delta\n",
    "                    else:\n",
    "                        model_Q2[feature]+= (1.0-prob)*delta\n",
    "                elif t=='ham':\n",
    "                    if feature not in model_Q2:\n",
    "                        model_Q2[feature] = (-prob)*delta\n",
    "                    else:\n",
    "                        model_Q2[feature]-= prob*delta\n",
    "        yield model_Q2#return a generator containing all (features,weights) pairs\n",
    "    \n",
    "    \n",
    "    \n",
    "    if os.path.isdir(output_model):\n",
    "        shutil.rmtree(output_model) # Remove the previous model to create a new one\n",
    "    training_data = sc.textFile(training_dataset)#read dataset\n",
    "    total_data = training_data.count()\n",
    "    #assign random keys to each data point, sort it by the keys which shuffles the data and then repartition into 1 single partition\n",
    "    labelFeature_rdd = training_data.map(lambda line:line.split())\\\n",
    "                        .map(lambda line:(random.randint(0,total_data),(line[1],line[2:])))\\\n",
    "                        .sortByKey().map(lambda line:(line[1][0],line[1][1])).coalesce(1)\n",
    "    update_model = labelFeature_rdd.mapPartitions(update).flatMap(lambda line:[(int(k),v) for k,v in line.items()])#call function on whole partition\n",
    "    update_model.saveAsTextFile(output_model)#save the model as text file\n",
    "    #### Your Solution to Question 3 here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "# Your tests here\n",
    "spark_shuffled_SGD(output_model='models/group_x_model_shuffled')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": [
    "#### Question 4 (5/20  marks)\n",
    "\n",
    "Last but not least, you should write a Spark program that can be used to classify documents as spam or ham, using the classification models you produced.\n",
    "\n",
    "The test data, i.e., the document instances that you should classifiy, are located in the file\n",
    "* ``\n",
    "\n",
    "Each line in this file represents a document that needs to be classified as spam or ham.  The format of this file is identical to the format of the files that hold the training instances.\n",
    "\n",
    "Implement the function `spark_classify` below that will load a model (from a specified folder under `models`), classify all of the instances in a given test data file (`spam.test.qrels.txt` by default) using that model, and then output the results in the folder `results_path` using Spark's `saveAsTextFile`.   The contents of the output file should look like this:\n",
    "```\n",
    "(clueweb09-en0000-00-00142,spam,2.601624279252943,spam)\n",
    "(clueweb09-en0000-00-01005,ham,2.5654162439491004,spam)\n",
    "(clueweb09-en0000-00-01382,ham,2.5893946346394188,spam)\n",
    "```\n",
    "Each line of the output represents one test instance.   The first two fields are the document ID and the test label.  These are just copied from the test data.   The third field is the spamminess score of the document, produced by the spamminess function using the model you are classifying with.   The fourth field is the spam/ham prediction made by the model.\n",
    "\n",
    "Of course, your spam/ham classifier must **not** use the test label from the input when making its prediction.  The test labels are the \"ground truth\" against which your predictions are being compared.   Using them to make predictions would defeat the whole purpose of model-based classification.\n",
    "\n",
    "Make sure that classification of the test instances is done by Spark, not by your driver program.  Do ***not*** load the test instances or classification results into your driver program. You are however allowed to load the model weights into your driver program to distribute them as side data. \n",
    "Unlike model training, classification is easily parallelizable, since each document is classified independently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from spamminess import spamminess\n",
    "from math import exp\n",
    "import shutil, os\n",
    "\n",
    "def spark_classify(input_model='models/britney_model', test_dataset='', results_path='results/test_qrels/model_britney_predictions'):\n",
    "    \n",
    "    \n",
    "    if os.path.isdir(results_path):\n",
    "        shutil.rmtree(results_path) # Remove the previous results\n",
    "    test_data = sc.textFile(test_dataset)#read dataset\n",
    "    labelFeature_rdd = test_data.map(lambda line:line.split()).map(lambda line:(line[0],line[1],[int(i) for i in line[2:]]))#split lines into docID,label and features\n",
    "    curr_model = sc.textFile(input_model).map(eval).collectAsMap()#store model as dictionary\n",
    "    spam_scores = labelFeature_rdd.map(lambda line:(line[0],line[1],spamminess(line[2],curr_model)))#calculate spamminess score\n",
    "    spam_predictions = spam_scores.map(lambda line:(line[0],line[1],line[2],'spam' if (line[2])>=0 else 'ham'))#classify each doc based on spamminess score\n",
    "    spam_predictions.saveAsTextFile(results_path)#save predictions\n",
    "    #### Your Solution to Question 4 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison for Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cell below runs the program to compute the ROC value or more specifically (1-ROCA)% value for a given models predictions\n",
    "- As we can see below the results are different for \"Model X\" and \"Model X Shuffled\" even though its the same training file but I have only changed the order in which the training instances are read\n",
    "- This proves that shuffling around the data does effect the model weights and inturn effects the ROCA score i.e the performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "tags": [
     "instructions"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
